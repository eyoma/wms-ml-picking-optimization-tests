# -*- coding: utf-8 -*-
"""wms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1frURc_x9HA5N-MSZIctlAuaygIsky30Z
"""



"""# Task
Train and test a Markov Model using the data in "wms/synthetic_warehouse_picks_sample.csv" to predict the most efficient picking sequence for warehouse pickers.

## Data loading and initial exploration

### Subtask:
Load the data from the provided CSV file and perform initial exploration to understand its structure and content.

**Reasoning**:
Load the data and perform initial exploration as requested in the instructions.
"""

import pandas as pd

# Load the data
df = pd.read_csv("wms/synthetic_warehouse_picks_sample.csv")

# Display the first 5 rows


# Print column names and their data types
print(df.info())

# Display basic descriptive statistics


"""## Data preprocessing

### Subtask:
Prepare the data for modeling by handling missing values, converting data types, and structuring the data into sequences for the Markov model.

**Reasoning**:
Convert 'datetime_picked' to datetime objects, sort by 'order_id' and 'datetime_picked', group by 'order_id' and aggregate 'bin_id' into lists, and store the result in a new DataFrame.
"""

# Convert 'datetime_picked' to datetime objects
df['datetime_picked'] = pd.to_datetime(df['datetime_picked'])

# Sort the DataFrame by 'order_id' and 'datetime_picked'
df_sorted = df.sort_values(by=['order_id', 'datetime_picked'])

# Group by 'order_id' and aggregate 'bin_id' into lists
picking_sequences_df = df_sorted.groupby('order_id')['bin_id'].agg(list).reset_index()

# Display the first few picking sequences


"""## Markov model training

### Subtask:
Train a Markov model on the preprocessed picking sequence data to learn the transition probabilities between different bin locations.

**Reasoning**:
Define a function to calculate transition probabilities and apply it to the picking sequences data.
"""

def train_markov_model(sequences):
    """
    Trains a Markov model to learn transition probabilities between bin locations.

    Args:
        sequences: A list of lists, where each inner list represents a picking sequence
                   of bin locations for an order.

    Returns:
        A dictionary representing the transition probabilities.
        The keys are the current bin locations, and the values are another dictionary
        where keys are the next possible bin locations and values are their probabilities.
    """
    transitions = {}

    for sequence in sequences:
        for i in range(len(sequence) - 1):
            current_bin = sequence[i]
            next_bin = sequence[i+1]

            if current_bin not in transitions:
                transitions[current_bin] = {}

            if next_bin not in transitions[current_bin]:
                transitions[current_bin][next_bin] = 0

            transitions[current_bin][next_bin] += 1

    # Convert counts to probabilities
    for current_bin, next_bins in transitions.items():
        total_count = sum(next_bins.values())
        for next_bin, count in next_bins.items():
            transitions[current_bin][next_bin] = count / total_count

    return transitions

# Train the Markov model using the picking sequences
markov_model = train_markov_model(picking_sequences_df['bin_id'].tolist())

# Display a sample of the trained model
import json
# print(json.dumps(markov_model, indent=4))

"""## Sequence prediction

### Subtask:
Develop a method to use the trained Markov model to predict the most efficient picking sequence for a new order.

**Reasoning**:
Define a function to predict the optimal picking sequence using the trained Markov model and the list of bins for a new order.
"""

def predict_picking_sequence(markov_model, order_bins):
    """
    Predicts the most efficient picking sequence for a new order
    using the trained Markov model.

    Args:
        markov_model: A dictionary representing the transition probabilities.
        order_bins: A list of bin locations for the new order.

    Returns:
        A list representing the predicted efficient picking sequence.
    """
    if not order_bins:
        return []

    # Start with the first bin in the order as the current bin
    current_bin = order_bins[0]
    predicted_sequence = [current_bin]
    remaining_bins = set(order_bins[1:])

    while remaining_bins:
        next_bin = None
        highest_prob = -1

        # Check for transitions from the current bin to remaining bins in the model
        if current_bin in markov_model:
            for next_candidate in remaining_bins:
                if next_candidate in markov_model[current_bin]:
                    prob = markov_model[current_bin][next_candidate]
                    if prob > highest_prob:
                        highest_prob = prob
                        next_bin = next_candidate

        # If a transition is found in the model, select the bin with the highest probability
        if next_bin:
            predicted_sequence.append(next_bin)
            remaining_bins.remove(next_bin)
            current_bin = next_bin
        else:
            # Fallback: If no transition is found in the model,
            # append the next bin from the original order (if available)
            # or any remaining bin if the original order structure is not preserved.
            # For this implementation, we'll pick the first remaining bin.
            fallback_bin = remaining_bins.pop()
            predicted_sequence.append(fallback_bin)
            current_bin = fallback_bin # Update current_bin for the next iteration

    return predicted_sequence

# Example usage (using a sample order from the existing data for demonstration)
# Let's take the bins from the first order in picking_sequences_df
sample_order_bins = picking_sequences_df['bin_id'].iloc[0]
predicted_sequence = predict_picking_sequence(markov_model, sample_order_bins)

print("Original Order Bins:", sample_order_bins)
print("Predicted Picking Sequence:", predicted_sequence)

"""## Model evaluation (optional but recommended)

### Subtask:
If possible, devise a strategy to evaluate the performance of the Markov model in predicting efficient sequences. This might involve comparing predicted sequences with actual efficient sequences from experienced pickers or using simulation.

**Reasoning**:
Define a function to evaluate the predicted sequence against the actual sequence by calculating the number of matching consecutive bin transitions. Then, apply this evaluation method to a subset of the picking sequences to analyze the model's performance and discuss the limitations and alternatives.
"""

def evaluate_picking_sequence(actual_sequence, predicted_sequence):
    """
    Evaluates the predicted picking sequence against the actual sequence
    by counting matching consecutive bin transitions.

    Args:
        actual_sequence: A list representing the actual picking sequence.
        predicted_sequence: A list representing the predicted picking sequence.

    Returns:
        The number of matching consecutive bin transitions.
    """
    if not actual_sequence or not predicted_sequence:
        return 0

    min_len = min(len(actual_sequence), len(predicted_sequence))
    matching_transitions = 0

    for i in range(min_len - 1):
        if actual_sequence[i] == predicted_sequence[i] and actual_sequence[i+1] == predicted_sequence[i+1]:
            matching_transitions += 1

    return matching_transitions

# Apply the evaluation method to a subset of the picking sequences
# For demonstration, let's evaluate the first 100 predicted sequences against their actual sequences.
num_evaluations = 100
evaluation_results = []

for i in range(min(num_evaluations, len(picking_sequences_df))):
    actual_sequence = picking_sequences_df['bin_id'].iloc[i]
    predicted_sequence = predict_picking_sequence(markov_model, actual_sequence)
    matching_transitions = evaluate_picking_sequence(actual_sequence, predicted_sequence)
    evaluation_results.append(matching_transitions)

# Analyze the evaluation results
average_matching_transitions = sum(evaluation_results) / len(evaluation_results) if evaluation_results else 0

print(f"Average number of matching consecutive bin transitions over {len(evaluation_results)} sequences: {average_matching_transitions}")

# Discussion of limitations and alternatives
print("\nDiscussion of Evaluation Strategy Limitations and Alternatives:")
print("Limitations of the current evaluation method (matching consecutive transitions):")
print("- It only counts exact consecutive matches, potentially missing partially correct sequences.")
print("- It doesn't account for the overall distance or path efficiency.")
print("- It assumes the order of items in the actual sequence represents an 'efficient' sequence, which might not always be true without ground truth data on optimal paths.")

print("\nPotential alternative evaluation methods:")
print("- Levenshtein distance or other sequence similarity metrics to measure the overall difference between sequences.")
print("- Graph-based metrics: Represent the warehouse as a graph and calculate the shortest path distance between the actual and predicted sequences.")
print("- Simulation: Simulate picker movement based on actual and predicted sequences and compare total travel time or distance.")
print("- Expert validation: Have experienced pickers evaluate the predicted sequences for efficiency.")

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 13458 records with 6 columns: `order_id`, `item_id`, `datetime_picked`, `picker_id`, `warehouse_id`, and `bin_id`. All columns were initially of object data type, and there were no missing values.
*   The data was successfully preprocessed by converting `datetime_picked` to datetime objects and sorting the picks within each order by time.
*   Picking sequences were aggregated for each order, resulting in a DataFrame where each row represents an order with a list of bin IDs in the order they were picked.
*   A Markov model was trained to capture the transition probabilities between bin locations based on the historical picking sequences.
*   A prediction function was developed that uses the trained Markov model to predict the next bin location with the highest probability from the set of remaining bins in an order, employing a greedy approach. A fallback mechanism is included for cases where no transition is found in the model.
*   An evaluation strategy was implemented to compare predicted sequences with actual sequences by counting the number of matching consecutive bin transitions.
*   Evaluating the first 100 predicted sequences against their corresponding actual sequences showed an average of 0.65 matching consecutive bin transitions.

### Insights or Next Steps

*   The current evaluation metric provides a basic measure of sequence similarity but does not fully capture the efficiency of the predicted path in terms of distance or time. Future work should explore more robust evaluation metrics like graph-based distance calculations or simulation to better assess the model's real-world performance in predicting efficient picking routes.
*   Consider incorporating additional features into the model, such as warehouse layout information (distances between bins), picker performance data, or item characteristics, to potentially improve the accuracy and efficiency of predicted picking sequences beyond simple bin-to-bin transition probabilities.

"""